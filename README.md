# BigDataOps

🚀 **Entorno Docker Compose todo-en-uno para operaciones Big Data**, incluyendo **Hadoop**, **Spark**, **Hive**, **Hue** y **Airflow**. Ideal para **aprendizaje**, **desarrollo** y **pruebas**.

Incluye flujos de trabajo de ejemplo, una configuración rápida y una fácil personalización, lo que lo convierte en una solución ideal para aprender, desarrollar y probar en **Big DataOps**.

---

## ✨ Características clave

- 🔗 **Herramientas de Big Data totalmente integradas**: Preconfigurado y listo para usar, incluyendo **Hadoop** para almacenamiento y procesamiento distribuido, **Spark** para análisis de Big Data, **Hive** para consultas SQL, **Hue** como interfaz gráfica web, y **Airflow** para orquestar complejos flujos de datos.
- ⚡ **Configuración rápida**: Comienza con un solo comando `make start-all`. Olvídate de las configuraciones tediosas y los problemas de dependencias.
- 🛠️ **Uso versátil**: Ideal para **aprendizaje**, **desarrollo**, **pruebas** y entornos de **producción a pequeña escala**.
- 📂 **Flujos de trabajo de ejemplo**: Incluye trabajos y scripts de muestra para demostrar las capacidades del stack, ayudándote a arrancar con tus proyectos de Big Data rápidamente.
- 🔧 **Personalizable**: Fácil de extender o modificar el stack para adaptarlo a tus casos de uso específicos.

---

## 💡 ¿Por qué utilizar este repositorio?

- 🎯 **Facilidad de uso**: Simplifica el proceso de configuración, para que puedas centrarte en desarrollar y probar tus soluciones de Big Data.
- 🧩 **Solución todo en uno**: No es necesario integrar herramientas por separado; todo está empaquetado en una única solución coherente.
- 🌍 **Comunidad**: Diseñado para ser accesible, bien documentado y fácil de descubrir, con el objetivo de convertirse en un recurso clave para Big DataOps en Docker.

---

## 📖 ¿Cómo usarlo?

Asegúrate de tener instalado **Docker** y **Make**.

Puedes encontrar comandos útiles en el archivo `Makefile`.

Para desplegar toda la infraestructura, simplemente ejecuta:

```bash
make start-all
```

---

✨ **¡Ahora estás listo para sumergirte en el mundo del Big Data!**


